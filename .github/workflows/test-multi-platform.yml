name: SWHID Testing Harness (Multi-Platform)

on:
  schedule:
    - cron: "17 2 * * *"  # Nightly run at 2:17 AM UTC
  workflow_dispatch:  # Allow manual triggering from GitHub Actions UI

jobs:
  check-changes:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read  # Required to list workflow runs and artifacts
    outputs:
      changes_detected: ${{ steps.check-changes.outputs.changes_detected }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
          cache: 'pip'  # Automatically cache pip packages
          # Note: setup-python@v5 handles pip caching automatically, no need for explicit cache step
      
      - name: Install Software Heritage Python tools
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install swh.model swh.core || echo "Warning: swh Python tools not available"
        continue-on-error: true
      
      - name: Set up Ruby (for version checking)
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.2'
          bundler-cache: false
        continue-on-error: true
      
      - name: Find previous workflow run
        id: find-previous-run
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            try {
              // Get workflow file name from context
              const workflowFile = context.workflow;
              console.log(`Looking for workflow: ${workflowFile}`);
              
              // Try to get workflow runs - use workflow file name or workflow ID
              let workflowRuns;
              try {
                workflowRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                  workflow_id: workflowFile,
                status: 'success',
                per_page: 2
              });
              } catch (workflowError) {
                // If workflow_id doesn't work, try using the workflow file path
                console.log(`First attempt failed: ${workflowError.message}`);
                console.log(`Trying with workflow file path instead...`);
                workflowRuns = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: '.github/workflows/test-multi-platform.yml',
                  status: 'success',
                  per_page: 2
                });
              }
              
              if (!workflowRuns.data.workflow_runs || workflowRuns.data.workflow_runs.length < 2) {
                console.log('No previous successful run found');
                core.setOutput('artifact_id', '');
                return;
              }
              
              const previousRun = workflowRuns.data.workflow_runs[1];
              console.log(`Found previous run: ${previousRun.id}`);
              
              const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: previousRun.id
              });
              
              const upstreamStateArtifact = artifacts.data.artifacts.find(a => a.name === 'upstream-state');
              
              if (!upstreamStateArtifact) {
                console.log('upstream-state artifact not found in previous run');
                core.setOutput('artifact_id', '');
                return;
              }
              
              console.log(`Found upstream-state artifact: ${upstreamStateArtifact.id}`);
              core.setOutput('artifact_id', upstreamStateArtifact.id.toString());
            } catch (error) {
              console.log(`Error finding previous run: ${error.message}`);
              console.log(`Error stack: ${error.stack}`);
              core.setOutput('artifact_id', '');
            }
      
      - name: Download previous run state (if available)
        if: steps.find-previous-run.outputs.artifact_id != ''
        shell: bash
        continue-on-error: true
        run: |
          mkdir -p previous-state
          ARTIFACT_ID="${{ steps.find-previous-run.outputs.artifact_id }}"
          
          curl -L -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${ARTIFACT_ID}/zip" \
            -o /tmp/upstream-state.zip
          
          if [ -f /tmp/upstream-state.zip ] && [ -s /tmp/upstream-state.zip ]; then
            unzip -q /tmp/upstream-state.zip -d /tmp/ 2>/dev/null || true
            if [ -d /tmp/upstream-state ]; then
              mv /tmp/upstream-state/* previous-state/ 2>/dev/null || true
              rmdir /tmp/upstream-state 2>/dev/null || true
            fi
            echo "Successfully downloaded previous state"
          else
            echo "Failed to download artifact or artifact is empty"
            mkdir -p previous-state
          fi
      
      - name: Check for upstream changes
        id: check-changes
        shell: bash
        run: |
          echo "## üîç Checking for Upstream Changes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CHANGES_DETECTED=false
          
          # Get current state
          CURRENT_TEST_SUITE_SHA=$(git rev-parse HEAD)
          CURRENT_SWH_MODEL_VERSION=""
          CURRENT_SWH_CORE_VERSION=""
          CURRENT_SWHID_GEM_VERSION=""
          
          # Check changes in test-suite repository
          echo "### Test Suite Repository" >> $GITHUB_STEP_SUMMARY
          if [ -f previous-state/test-suite-sha.txt ]; then
            PREVIOUS_SHA=$(cat previous-state/test-suite-sha.txt)
            if [ "$CURRENT_TEST_SUITE_SHA" != "$PREVIOUS_SHA" ]; then
              echo "‚ö†Ô∏è **Changes detected in test-suite repository**" >> $GITHUB_STEP_SUMMARY
              echo "Previous: \`${PREVIOUS_SHA:0:7}\` ‚Üí Current: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
              echo "Recent commits:" >> $GITHUB_STEP_SUMMARY
              git log --oneline ${PREVIOUS_SHA}..${CURRENT_TEST_SUITE_SHA} | head -5 >> $GITHUB_STEP_SUMMARY || true
              CHANGES_DETECTED=true
            else
              echo "‚úÖ No changes in test-suite repository" >> $GITHUB_STEP_SUMMARY
              echo "Current commit: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ÑπÔ∏è No previous state found (first run or artifact expired)" >> $GITHUB_STEP_SUMMARY
            echo "Current commit: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
            CHANGES_DETECTED=true
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check for updates in swh Python packages
          echo "### Software Heritage Python Packages" >> $GITHUB_STEP_SUMMARY
          PACKAGES="swh.model swh.core"
          for package in $PACKAGES; do
            INSTALLED_VERSION=$(pip show $package 2>/dev/null | grep "^Version:" | awk '{print $2}' || echo "not installed")
            if [ "$INSTALLED_VERSION" != "not installed" ]; then
              if [ "$package" = "swh.model" ]; then
                CURRENT_SWH_MODEL_VERSION="$INSTALLED_VERSION"
              elif [ "$package" = "swh.core" ]; then
                CURRENT_SWH_CORE_VERSION="$INSTALLED_VERSION"
              fi
              
              if [ -f previous-state/${package}-version.txt ]; then
                PREVIOUS_VERSION=$(cat previous-state/${package}-version.txt)
                if [ "$INSTALLED_VERSION" != "$PREVIOUS_VERSION" ]; then
                  echo "‚ö†Ô∏è **$package**: Previous: \`$PREVIOUS_VERSION\` ‚Üí Current: \`$INSTALLED_VERSION\`" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                else
                  echo "‚úÖ **$package**: \`$INSTALLED_VERSION\` (unchanged)" >> $GITHUB_STEP_SUMMARY
                fi
              else
                LATEST_VERSION=$(pip index versions $package 2>/dev/null | grep "LATEST:" | awk '{print $2}' || echo "")
                if [ -n "$LATEST_VERSION" ] && [ "$INSTALLED_VERSION" != "$LATEST_VERSION" ]; then
                  echo "‚ö†Ô∏è **$package**: Installed: \`$INSTALLED_VERSION\`, Latest: \`$LATEST_VERSION\`" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                else
                  echo "‚úÖ **$package**: \`$INSTALLED_VERSION\` (latest)" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            else
              echo "‚ÑπÔ∏è **$package**: Not installed" >> $GITHUB_STEP_SUMMARY
            fi
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check for updates in Ruby gem
          echo "### Ruby Gem (swhid)" >> $GITHUB_STEP_SUMMARY
          if command -v gem >/dev/null 2>&1; then
            # Get latest version from RubyGems without installing
            # gem search -r swhid outputs: "swhid (X.Y.Z)" or "swhid (X.Y.Z, X.Y.Z-1, ...)"
            GEM_SEARCH_OUTPUT=$(gem search -r -e swhid 2>/dev/null | grep -E "^swhid\s" | head -1 || echo "")
            if [ -n "$GEM_SEARCH_OUTPUT" ]; then
              # Extract version: "swhid (1.2.3)" -> "1.2.3"
              LATEST_GEM_VERSION=$(echo "$GEM_SEARCH_OUTPUT" | sed -E 's/^swhid\s+\(([^,)]+).*\)$/\1/' | xargs)
              if [ -n "$LATEST_GEM_VERSION" ]; then
                CURRENT_SWHID_GEM_VERSION="$LATEST_GEM_VERSION"
                if [ -f previous-state/swhid-gem-version.txt ]; then
                  PREVIOUS_VERSION=$(cat previous-state/swhid-gem-version.txt)
                  if [ "$LATEST_GEM_VERSION" != "$PREVIOUS_VERSION" ]; then
                    echo "‚ö†Ô∏è **swhid gem**: Previous: \`$PREVIOUS_VERSION\` ‚Üí Current: \`$LATEST_GEM_VERSION\`" >> $GITHUB_STEP_SUMMARY
                    CHANGES_DETECTED=true
                  else
                    echo "‚úÖ **swhid gem**: \`$LATEST_GEM_VERSION\` (unchanged)" >> $GITHUB_STEP_SUMMARY
                  fi
                else
                  echo "‚ÑπÔ∏è **swhid gem**: \`$LATEST_GEM_VERSION\` (first check)" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                fi
              else
                echo "‚ÑπÔ∏è **swhid gem**: Could not parse version from: $GEM_SEARCH_OUTPUT" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "‚ÑπÔ∏è **swhid gem**: Could not find gem in RubyGems" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ÑπÔ∏è **swhid gem**: Ruby/gem not available for version checking" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Summary
          if [ "$CHANGES_DETECTED" = "true" ]; then
            echo "### üìä Summary" >> $GITHUB_STEP_SUMMARY
            echo "‚ö†Ô∏è **Changes detected upstream** - Test suite will run" >> $GITHUB_STEP_SUMMARY
            echo "changes_detected=true" >> $GITHUB_OUTPUT
          else
            echo "### üìä Summary" >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ **No upstream changes detected** - Skipping test suite to save resources" >> $GITHUB_STEP_SUMMARY
            echo "changes_detected=false" >> $GITHUB_OUTPUT
          fi
          
          # Save current state for next run
          mkdir -p current-state
          echo "$CURRENT_TEST_SUITE_SHA" > current-state/test-suite-sha.txt
          if [ -n "$CURRENT_SWH_MODEL_VERSION" ]; then
            echo "$CURRENT_SWH_MODEL_VERSION" > current-state/swh.model-version.txt
          fi
          if [ -n "$CURRENT_SWH_CORE_VERSION" ]; then
            echo "$CURRENT_SWH_CORE_VERSION" > current-state/swh.core-version.txt
          fi
          if [ -n "$CURRENT_SWHID_GEM_VERSION" ]; then
            echo "$CURRENT_SWHID_GEM_VERSION" > current-state/swhid-gem-version.txt
          fi
        continue-on-error: true
      
      - name: Upload current state for next run
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: upstream-state
          path: current-state
          retention-days: 90
        continue-on-error: true

  test:
    needs: check-changes
    if: needs.check-changes.outputs.changes_detected == 'true'
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-24.04, macos-14, windows-2022]
        python-version: ["3.12"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for commit info
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'  # Automatically cache pip packages
          # Note: setup-python@v5 handles pip caching automatically, no need for explicit cache step
      
      - name: Cache Homebrew packages (macOS)
        if: runner.os == 'macOS'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          # Cache Homebrew's download cache
          path: |
            ~/Library/Caches/Homebrew
          key: brew-${{ runner.os }}-libgit2-pkgconfig-openssl
          restore-keys: |
            brew-${{ runner.os }}-
      
      - name: Cache vcpkg packages (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@v4
        continue-on-error: true
        with:
          # Cache vcpkg's built packages, downloads, and binary cache
          # This significantly speeds up Windows builds by avoiding recompilation
          path: |
            C:\vcpkg\packages
            C:\vcpkg\downloads
            C:\vcpkg\buildtrees
            C:\Users\${{ runner.user }}\AppData\Local\vcpkg\archives
          key: vcpkg-Windows-libgit2-x64-windows
          restore-keys: |
            vcpkg-Windows-
      
      - name: Install system dependencies
        shell: bash
        run: |
          if [ "$RUNNER_OS" == "Linux" ]; then
            sudo apt-get update
            sudo apt-get install -y libgit2-dev pkg-config libssl-dev
          elif [ "$RUNNER_OS" == "macOS" ]; then
            brew install libgit2 pkg-config openssl 2>&1 | grep -vE "(Warning:.*is already installed|To reinstall)" || true
          elif [ "$RUNNER_OS" == "Windows" ]; then
            # On Windows, libgit2 is optional - pygit2 can work without it in some cases
            # Try to install via vcpkg, but don't fail if it doesn't work
            # vcpkg may already be installed on the runner (check C:\vcpkg or C:\tools\vcpkg)
            VCPKG_PATH=""
            if [ -d "C:/vcpkg" ]; then
              VCPKG_PATH="C:/vcpkg"
              export PATH="$VCPKG_PATH:$PATH"
              echo "Found vcpkg at C:/vcpkg"
            elif [ -d "C:/tools/vcpkg" ]; then
              VCPKG_PATH="C:/tools/vcpkg"
              export PATH="$VCPKG_PATH:$PATH"
              echo "Found vcpkg at C:/tools/vcpkg"
            elif command -v vcpkg &> /dev/null; then
              VCPKG_PATH=$(command -v vcpkg)
              echo "Found vcpkg in PATH: $VCPKG_PATH"
            elif command -v choco &> /dev/null; then
              echo "Installing vcpkg via Chocolatey..."
              choco install -y vcpkg || echo "Warning: vcpkg installation failed, continuing without libgit2"
              if [ -d "C:/vcpkg" ]; then
                VCPKG_PATH="C:/vcpkg"
                export PATH="$VCPKG_PATH:$PATH"
              elif command -v vcpkg &> /dev/null; then
                VCPKG_PATH=$(command -v vcpkg)
              fi
            else
              echo "Warning: Chocolatey not available, trying to use vcpkg if already installed"
            fi
            
            # Install libgit2 if vcpkg is available
            if [ -n "$VCPKG_PATH" ] || command -v vcpkg &> /dev/null; then
              echo "Installing libgit2 via vcpkg (this may take a while on first run, but will be cached)..."
              vcpkg install libgit2:x64-windows --recurse || echo "Warning: libgit2 installation failed, continuing without it"
            else
              echo "Warning: vcpkg not found, libgit2 may not be available"
            fi
          fi
        continue-on-error: true
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev] psutil
      
      - name: Install Software Heritage Python tools
        shell: bash
        run: |
          if [ "$RUNNER_OS" == "Windows" ]; then
            # swh.core has test data files with colons in names, which Windows doesn't support
            # swh.model is sufficient for the python implementation
            pip install swh.model || echo "Warning: swh.model not available, python implementation will be skipped"
          else
            pip install swh.model swh.core || echo "Warning: swh Python tools not available, some implementations may be skipped"
          fi
        continue-on-error: true
      
      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.2'
          bundler-cache: false
        continue-on-error: true
      
      - name: Cache swhid gem
        id: cache-swhid-gem
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.gem/ruby
            ~/.local/share/gem
            ${{ runner.toolCache }}/Ruby/*/x64/lib/ruby/gems
            ${{ runner.toolCache }}/Ruby/*/x64/bin
          # Note: Cache key doesn't include version - we validate after restore
          # On Windows, runner.toolCache is C:\hostedtoolcache\windows
          # On Linux/macOS, runner.toolCache is /opt/hostedtoolcache or /Users/runner/hostedtoolcache
          key: swhid-gem-${{ runner.os }}-ruby-3.2
          restore-keys: |
            swhid-gem-${{ runner.os }}-ruby-3.2
            swhid-gem-${{ runner.os }}-ruby-3.2-
            swhid-gem-${{ runner.os }}-
      
      - name: Determine CPU cores
        id: cpu-cores
        shell: bash
        run: |
          if command -v nproc >/dev/null 2>&1; then
            CORES=$(nproc)
          elif command -v sysctl >/dev/null 2>&1; then
            CORES=$(sysctl -n hw.ncpu)
          elif command -v getconf >/dev/null 2>&1; then
            CORES=$(getconf _NPROCESSORS_ONLN)
          else
            CORES=4
          fi
          echo "cores=${CORES}" >> $GITHUB_OUTPUT
          echo "Using parallel compilation with ${CORES} cores"
      
      - name: Install swhid gem
        shell: bash
        run: |
          # Get cores from previous step (with fallback)
          CORES="${{ steps.cpu-cores.outputs.cores }}"
          if [ -z "${CORES}" ] || [ "${CORES}" = "" ]; then
            # Fallback if output not available
            if command -v nproc >/dev/null 2>&1; then
              CORES=$(nproc)
            elif command -v sysctl >/dev/null 2>&1; then
              CORES=$(sysctl -n hw.ncpu)
            else
              CORES=4
            fi
          fi
          
          # Unset any existing MAKE variable that might have wrong value
          unset MAKE || true
          
          # Set MAKE with evaluated cores value
          export MAKE="make -j${CORES}"
          echo "MAKE variable set to: ${MAKE}"
          echo "Verifying MAKE variable:"
          echo "${MAKE}" | head -1
          
          # Check cache restore status first
          echo "=== Gem cache status ==="
          echo "cache-hit=${{ steps.cache-swhid-gem.outputs.cache-hit }}"
          
          # Verify cache was actually restored by checking if gem files exist
          echo "Checking for cached gem files..."
          CACHED_GEM_FOUND=false
          if [ -d ~/.local/share/gem/ruby/3.2.0/gems/swhid-* ] 2>/dev/null || \
             [ -d ~/.gem/ruby/3.2.0/gems/swhid-* ] 2>/dev/null || \
             [ -d "${{ runner.toolCache }}/Ruby"/*/x64/lib/ruby/gems/3.2.0/gems/swhid-* ] 2>/dev/null; then
            CACHED_GEM_FOUND=true
            echo "‚úÖ Found cached gem files in cache directories"
            find ~/.local/share/gem ~/.gem "${{ runner.toolCache }}/Ruby" -type d -name "swhid-*" 2>/dev/null | head -3 || true
          else
            echo "‚ö†Ô∏è No cached gem files found in cache directories"
          fi
          
          # Check if gem is already installed and validate version
          INSTALLED_VERSION=""
          GEM_AVAILABLE=false
          
          # Note: cache-hit is only true for exact key matches
          # When restore-keys match, cache is restored but cache-hit=false
          # So we check if gem is actually available, not just cache-hit status
          if gem list -i swhid >/dev/null 2>&1; then
            INSTALLED_VERSION=$(gem list swhid | grep -E "^\s*swhid\s" | sed -E 's/^\s*swhid\s+\(([^)]+)\).*/\1/' | head -1 || echo "")
            echo "swhid gem found in cache: version ${INSTALLED_VERSION}"
            
            # Verify gem is actually usable (not just listed)
            if ruby -r swhid -e "true" 2>/dev/null; then
              GEM_AVAILABLE=true
              echo "Verified: Cached gem is usable"
            else
              echo "Warning: Cached gem is listed but not usable, will reinstall"
              GEM_AVAILABLE=false
            fi
          else
            # Cache might have been restored but gem not found yet
            # This can happen if cache paths don't match Ruby's gem paths exactly
            if [ "$CACHED_GEM_FOUND" = "true" ]; then
              echo "‚ö†Ô∏è Cached gem files found but gem not recognized by 'gem list'"
              echo "This may indicate Ruby needs to reload gem paths - will reinstall to ensure gem is available"
            elif [ "${{ steps.cache-swhid-gem.outputs.cache-hit }}" = "true" ]; then
              echo "‚ö†Ô∏è Cache was restored (cache-hit=true) but gem files not found"
              echo "Cache may be empty or corrupted - will reinstall"
            else
              echo "Gem not found via 'gem list'"
            fi
          fi
          
          # Get latest available version
          GEM_SEARCH_OUTPUT=$(gem search -r -e swhid 2>/dev/null | grep -E "^swhid\s" | head -1 || echo "")
          if [ -n "$GEM_SEARCH_OUTPUT" ]; then
            LATEST_VERSION=$(echo "$GEM_SEARCH_OUTPUT" | sed -E 's/^swhid\s+\(([^,)]+).*\)$/\1/' | xargs)
            echo "Latest available swhid gem version: ${LATEST_VERSION}"
            
            # Check if we need to reinstall
            if [ -n "$INSTALLED_VERSION" ] && [ "$INSTALLED_VERSION" = "$LATEST_VERSION" ] && [ "$GEM_AVAILABLE" = "true" ]; then
              echo "Cached gem version (${INSTALLED_VERSION}) matches latest and is usable, using cache"
              gem list swhid
            else
              if [ -n "$INSTALLED_VERSION" ]; then
                echo "Cached gem version (${INSTALLED_VERSION}) differs from latest (${LATEST_VERSION}), reinstalling..."
              else
                echo "Installing swhid gem (this may take a while for native extensions)..."
              fi
              # Uninstall old version if exists, then install latest
              gem uninstall swhid -x 2>/dev/null || true
              env MAKE="${MAKE}" gem install swhid --no-document || echo "Warning: swhid gem not available, Ruby implementation will be skipped"
            fi
          else
            # Fallback: if we can't check version, use cached gem if available and usable
            if [ -n "$INSTALLED_VERSION" ] && [ "$GEM_AVAILABLE" = "true" ]; then
              echo "Cannot check latest version, using cached gem (${INSTALLED_VERSION})"
              gem list swhid
            else
              echo "Installing swhid gem (this may take a while for native extensions)..."
              env MAKE="${MAKE}" gem install swhid --no-document || echo "Warning: swhid gem not available, Ruby implementation will be skipped"
            fi
          fi
          
          # Ensure gem bin directory is in PATH for harness to find swhid command
          # ruby/setup-ruby should do this, but let's be explicit
          set +e  # Temporarily disable exit on error for detection logic
          
          # Method 1: Use gem env to get executable directory
          # On Windows, gem env outputs paths with forward slashes, handle both formats
          GEM_BIN_DIR=$(gem env 2>/dev/null | grep -E "EXECUTABLE DIRECTORY" | sed -E 's/.*EXECUTABLE DIRECTORY[^:]*: *//' 2>/dev/null | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | head -1 || echo "")
          
          # Method 2: Try Gem.user_dir
          if [ -z "$GEM_BIN_DIR" ] || [ ! -d "$GEM_BIN_DIR" ]; then
            GEM_USER_DIR=$(ruby -e "puts Gem.user_dir" 2>/dev/null || echo "")
            if [ -n "$GEM_USER_DIR" ] && [ "$GEM_USER_DIR" != "" ]; then
              GEM_BIN_DIR="$GEM_USER_DIR/bin"
            fi
          fi
          
          # Method 2b: Check GEM_HOME environment variable (set by ruby/setup-ruby)
          if [ -z "$GEM_BIN_DIR" ] || [ ! -d "$GEM_BIN_DIR" ]; then
            if [ -n "$GEM_HOME" ] && [ -d "$GEM_HOME/bin" ]; then
              GEM_BIN_DIR="$GEM_HOME/bin"
              echo "Using GEM_HOME/bin: $GEM_BIN_DIR"
            fi
          fi
          
          # Method 3: Search for swhid executable and use its directory
          if [ -z "$GEM_BIN_DIR" ] || [ ! -d "$GEM_BIN_DIR" ] || [ ! -f "$GEM_BIN_DIR/swhid" ]; then
            # Platform-specific search paths
            if [ "$RUNNER_OS" == "macOS" ]; then
              # macOS: Check Homebrew paths and tool cache
              SWHID_PATH=$(find ~/.local/share/gem ~/.gem /opt/hostedtoolcache/Ruby "$HOME/Library/Ruby" /opt/homebrew/lib/ruby -name swhid -type f 2>/dev/null | head -1 || echo "")
            elif [ "$RUNNER_OS" == "Windows" ]; then
              # Windows: Check tool cache and user directories
              SWHID_PATH=$(find ~/.local/share/gem ~/.gem /opt/hostedtoolcache/Ruby "$HOME/AppData/Local/Programs/Ruby" -name swhid -type f 2>/dev/null | head -1 || echo "")
            else
              # Linux: Standard paths
              SWHID_PATH=$(find ~/.local/share/gem ~/.gem /opt/hostedtoolcache/Ruby -name swhid -type f 2>/dev/null | head -1 || echo "")
            fi
            
            if [ -n "$SWHID_PATH" ] && [ "$SWHID_PATH" != "" ]; then
              GEM_BIN_DIR=$(dirname "$SWHID_PATH")
              echo "Found swhid at: $SWHID_PATH"
            fi
          fi
          
          # Method 4: Try common locations (platform-specific)
          if [ -z "$GEM_BIN_DIR" ] || [ ! -d "$GEM_BIN_DIR" ]; then
            if [ "$RUNNER_OS" == "macOS" ]; then
              # macOS: Check Homebrew and tool cache locations
              for dir in ~/.local/share/gem/ruby/*/bin ~/.gem/ruby/*/bin /opt/hostedtoolcache/Ruby/*/x64/lib/ruby/gems/*/bin "$HOME/Library/Ruby"/*/bin /opt/homebrew/lib/ruby/gems/*/bin; do
                if [ -d "$dir" ] && [ -f "$dir/swhid" ] 2>/dev/null; then
                  GEM_BIN_DIR="$dir"
                  echo "Found swhid in: $dir"
                  break
                fi
              done
            elif [ "$RUNNER_OS" == "Windows" ]; then
              # Windows: Check tool cache and user directories
              for dir in ~/.local/share/gem/ruby/*/bin ~/.gem/ruby/*/bin /opt/hostedtoolcache/Ruby/*/x64/lib/ruby/gems/*/bin "$HOME/AppData/Local/Programs/Ruby"/*/bin; do
                if [ -d "$dir" ] && [ -f "$dir/swhid" ] 2>/dev/null; then
                  GEM_BIN_DIR="$dir"
                  echo "Found swhid in: $dir"
                  break
                fi
              done
            else
              # Linux: Standard paths
              for dir in ~/.local/share/gem/ruby/*/bin ~/.gem/ruby/*/bin /opt/hostedtoolcache/Ruby/*/x64/lib/ruby/gems/*/bin; do
                if [ -d "$dir" ] && [ -f "$dir/swhid" ] 2>/dev/null; then
                  GEM_BIN_DIR="$dir"
                  echo "Found swhid in: $dir"
                  break
                fi
              done
            fi
          fi
          
          set -e  # Re-enable exit on error
          
          # Add to PATH if found
          if [ -n "$GEM_BIN_DIR" ] && [ "$GEM_BIN_DIR" != "" ] && [ -d "$GEM_BIN_DIR" ]; then
            # Add to GITHUB_PATH (affects subsequent steps)
            echo "$GEM_BIN_DIR" >> $GITHUB_PATH
            # Also add to current PATH for this step
            export PATH="$GEM_BIN_DIR:$PATH"
            echo "‚úÖ Added gem bin directory to PATH: $GEM_BIN_DIR"
          else
            echo "‚ö†Ô∏è Warning: Could not determine gem bin directory"
            echo "Gem environment:"
            gem env 2>/dev/null | grep -E "(EXECUTABLE|INSTALLATION)" || true
          fi
          
          # Verify swhid command is accessible
          if command -v swhid >/dev/null 2>&1; then
            echo "‚úÖ swhid command found in PATH: $(which swhid)"
          else
            echo "‚ö†Ô∏è Warning: swhid command not found in PATH, but gem is installed"
            echo "Gem bin directory: $GEM_BIN_DIR"
            echo "Searching for swhid command..."
            find ~/.local/share/gem ~/.gem /opt/hostedtoolcache/Ruby -name swhid -type f 2>/dev/null | head -5 || echo "Not found in common locations"
            echo "Current PATH: $PATH"
          fi
        continue-on-error: true
      
      - name: Configure Git for SWHID testing
        shell: bash
        run: |
          # Configure Git to preserve line endings and file permissions for SWHID testing
          # This ensures consistent hashing across platforms
          git config --global core.autocrlf false
          git config --global core.filemode true
          git config --global core.precomposeunicode false
          git config --global core.quotepath false
          echo "Git configured for SWHID testing"
      
      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable
        continue-on-error: true
      
      - name: Cache Cargo registry and git cache
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
          key: cargo-${{ runner.os }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-
      
      - name: Cache swhid-rs build artifacts
        id: cache-swhid-rs
        uses: actions/cache/restore@v4
        continue-on-error: true
        with:
          # Use /tmp/swhid-rs/target - works on all platforms with bash shell
          # Try workflow-specific cache first, then fall back to generic cache
          # This allows both workflows to share caches while avoiding save conflicts
          # Note: Cache keys include commit hash from swhid-rs repo (format: key-<commit-hash>)
          # Since we don't know the commit hash yet (repo not cloned), we use restore-keys
          # restore-keys use prefix matching and return the most recently created cache
          # The commit marker file inside the cache will validate if it matches current commit
          path: /tmp/swhid-rs/target
          # Use a key that won't match - restore-keys will find the most recent cache with matching prefix
          # According to GitHub docs: if multiple caches match a restore-key, the most recently created is used
          key: swhid-rs-${{ runner.os == 'Linux' && 'Linux' || runner.os == 'macOS' && 'macOS' || 'Windows' }}-stable-multi-platform-workflow-${{ github.run_id }}-no-match
          restore-keys: |
            swhid-rs-${{ runner.os == 'Linux' && 'Linux' || runner.os == 'macOS' && 'macOS' || 'Windows' }}-stable-multi-platform-workflow-
            swhid-rs-${{ runner.os == 'Linux' && 'Linux' || runner.os == 'macOS' && 'macOS' || 'Windows' }}-stable-ubuntu-workflow-
            swhid-rs-${{ runner.os == 'Linux' && 'Linux' || runner.os == 'macOS' && 'macOS' || 'Windows' }}-stable-
            swhid-rs-${{ runner.os == 'Linux' && 'Linux' || runner.os == 'macOS' && 'macOS' || 'Windows' }}-
      
      - name: Check cache restore status
        shell: bash
        run: |
          echo "=== Cache restore status ==="
          echo "cache-hit=${{ steps.cache-swhid-rs.outputs.cache-hit }}"
          echo ""
          
          # Note: cache-hit is only true for exact key matches
          # When restore-keys match, cache is restored but cache-hit=false
          # So we check if the binary actually exists to determine if cache was restored
          if [ -d /tmp/swhid-rs/target/release ] && [ -f /tmp/swhid-rs/target/release/swhid ]; then
            echo "‚úÖ Cache was restored (binary found)"
            CACHED_COMMIT_FILE="/tmp/swhid-rs/target/.swhid-rs-commit"
            if [ -f "$CACHED_COMMIT_FILE" ]; then
              CACHED_COMMIT=$(cat "$CACHED_COMMIT_FILE" 2>/dev/null || echo "unknown")
              echo "‚úÖ Found cached binary for commit ${CACHED_COMMIT:0:7}"
              echo "Cached commit: $CACHED_COMMIT"
            else
              echo "‚ö†Ô∏è Found cached binary but no commit marker (will need validation)"
            fi
          elif [ "${{ steps.cache-swhid-rs.outputs.cache-hit }}" = "true" ]; then
            echo "‚úÖ Cache was restored (cache-hit=true, but binary not found - may need rebuild)"
          else
            echo "‚ùå Cache was not restored (cache-hit=false and binary not found)"
          fi
        continue-on-error: true
      
      - name: Fix binary permissions after cache restore
        shell: bash
        run: |
          echo "=== Ensuring binary is executable ==="
          # When cache is restored, file permissions might not be preserved correctly
          # Ensure the swhid binary is executable
          if [ -f /tmp/swhid-rs/target/release/swhid ]; then
            echo "Setting execute permissions on cached binary..."
            chmod +x /tmp/swhid-rs/target/release/swhid
            echo "‚úÖ Binary permissions fixed"
            ls -l /tmp/swhid-rs/target/release/swhid || true
          else
            echo "No binary found yet (will be built or permissions set during build)"
          fi
        continue-on-error: true
      
      - name: Setup SSH for private repository access (optional)
        shell: bash
        run: |
          mkdir -p ~/.ssh
          if [ -n "${{ secrets.SWHID_RS_SSH_KEY }}" ]; then
            echo "${{ secrets.SWHID_RS_SSH_KEY }}" > ~/.ssh/id_rsa
            chmod 600 ~/.ssh/id_rsa
            ssh-keyscan github.com >> ~/.ssh/known_hosts 2>/dev/null
            echo "SSH key configured for repository access"
          else
            echo "No SSH key provided - using public HTTPS access"
          fi
        continue-on-error: true
      
      - name: Clone and build swhid-rs
        id: swhid-rs-setup
        shell: bash
        env:
          SWHID_RS_REPO: ${{ secrets.SWHID_RS_REPO || 'https://github.com/swhid/swhid-rs.git' }}
          SWHID_RS_TOKEN: ${{ secrets.SWHID_RS_TOKEN }}
        run: |
          set +e
          # Preserve cached target/ directory if it exists
          if [ -d /tmp/swhid-rs/target ]; then
            echo "Preserving cached build artifacts..."
            mkdir -p /tmp/swhid-rs-cache-backup
            mv /tmp/swhid-rs/target /tmp/swhid-rs-cache-backup/ || true
          fi
          
          # Clean up any existing /tmp/swhid-rs directory
          if [ -d /tmp/swhid-rs ]; then
            echo "Cleaning up existing /tmp/swhid-rs directory..."
            rm -rf /tmp/swhid-rs
          fi
          
          # Try to clone the swhid-rs repository
          if [ -n "$SWHID_RS_REPO" ]; then
            echo "Attempting to clone swhid-rs from $SWHID_RS_REPO"
            # Use HTTPS with token if available (for private repos, or public access if no token)
            if [[ "$SWHID_RS_REPO" == https://* ]]; then
              # Force HTTPS by disabling SSH and avoiding system Git configs
              echo "=== Debug: Git configuration before clone ==="
              echo "Git version: $(git --version)"
              echo "GIT_SSH_COMMAND: ${GIT_SSH_COMMAND:-<unset>}"
              echo "GIT_CONFIG_NOSYSTEM: ${GIT_CONFIG_NOSYSTEM:-<unset>}"
              echo "SSH key exists: $([ -f ~/.ssh/id_rsa ] && echo 'yes' || echo 'no')"
              git config --global --list 2>/dev/null | grep -E "(url|ssh)" || echo "No global URL/SSH configs"
              git config --system --list 2>/dev/null | grep -E "(url|ssh)" || echo "No system URL/SSH configs"
              echo "Testing URL parsing..."
              echo "Original URL: $SWHID_RS_REPO"
              echo "=== End debug ==="
              
              # Completely disable SSH for this operation
              unset GIT_SSH_COMMAND
              unset GIT_SSH
              export GIT_CONFIG_NOSYSTEM=1
              export GIT_SSH_VARIANT=simple
              export GIT_TERMINAL_PROMPT=0
              
              if [ -n "$SWHID_RS_TOKEN" ]; then
                # Use dedicated token for repository access (if needed for private repos)
                # Construct URL properly: extract domain and path, then rebuild with token
                REPO_URL="https://${SWHID_RS_TOKEN}@${SWHID_RS_REPO#https://}"
                echo "Using token for repository access"
                echo "Repository URL (masked): https://***@${SWHID_RS_REPO#https://}"
                echo "Attempting clone with explicit HTTPS..."
                # Unset GIT_SSH_COMMAND (don't set to empty string) and force HTTPS
                (unset GIT_SSH_COMMAND; unset GIT_SSH; GIT_CONFIG_NOSYSTEM=1 git clone "$REPO_URL" /tmp/swhid-rs 2>&1) | tee /tmp/swhid-rs-clone.log
                CLONE_EXIT_CODE=${PIPESTATUS[0]}
              elif [ -n "${{ secrets.GITHUB_TOKEN }}" ]; then
                # Fallback to GITHUB_TOKEN if available (for private repos)
                GITHUB_TOKEN_VALUE="${{ secrets.GITHUB_TOKEN }}"
                REPO_URL="https://${GITHUB_TOKEN_VALUE}@${SWHID_RS_REPO#https://}"
                echo "Using GITHUB_TOKEN for repository access"
                echo "Repository URL (masked): https://***@${SWHID_RS_REPO#https://}"
                echo "Attempting clone with explicit HTTPS..."
                (unset GIT_SSH_COMMAND; unset GIT_SSH; GIT_CONFIG_NOSYSTEM=1 git clone "$REPO_URL" /tmp/swhid-rs 2>&1) | tee /tmp/swhid-rs-clone.log
                CLONE_EXIT_CODE=${PIPESTATUS[0]}
              else
                # Use public access (works for public repositories)
                echo "No token available, using public HTTPS access"
                echo "Attempting clone with explicit HTTPS..."
                (unset GIT_SSH_COMMAND; unset GIT_SSH; GIT_CONFIG_NOSYSTEM=1 git clone "$SWHID_RS_REPO" /tmp/swhid-rs 2>&1) | tee /tmp/swhid-rs-clone.log
                CLONE_EXIT_CODE=${PIPESTATUS[0]}
              fi
            else
              # SSH URL - use SSH key if configured
              git clone "$SWHID_RS_REPO" /tmp/swhid-rs 2>&1 | tee /tmp/swhid-rs-clone.log
              CLONE_EXIT_CODE=${PIPESTATUS[0]}
            fi
            if [ $CLONE_EXIT_CODE -eq 0 ] && [ -d /tmp/swhid-rs ]; then
              cd /tmp/swhid-rs
              
              # Get the current commit hash of swhid-rs to check if we need to rebuild
              SWHID_RS_COMMIT=$(git rev-parse HEAD 2>/dev/null || echo "unknown")
              echo "swhid-rs commit: ${SWHID_RS_COMMIT:0:7}"
              
              # Restore cached target/ directory if it was preserved
              if [ -d /tmp/swhid-rs-cache-backup/target ]; then
                echo "Restoring cached build artifacts..."
                mv /tmp/swhid-rs-cache-backup/target . || true
                rm -rf /tmp/swhid-rs-cache-backup || true
              fi
              
              # Check if we have cached build artifacts and if they match current source
              # We check for the binary AND verify it was built from the same commit
              CACHED_COMMIT_FILE="target/.swhid-rs-commit"
              NEED_REBUILD=true
              REBUILT=false
              
              if [ -d target/release ] && [ -f target/release/swhid ]; then
                if [ -f "$CACHED_COMMIT_FILE" ]; then
                  CACHED_COMMIT=$(cat "$CACHED_COMMIT_FILE" 2>/dev/null || echo "")
                  if [ "$CACHED_COMMIT" = "$SWHID_RS_COMMIT" ]; then
                    echo "Using cached swhid-rs binary (commit ${SWHID_RS_COMMIT:0:7})"
                    BUILD_EXIT_CODE=0
                    NEED_REBUILD=false
                  else
                    echo "Cached binary is from different commit (cached: ${CACHED_COMMIT:0:7}, current: ${SWHID_RS_COMMIT:0:7})"
                    echo "Rebuilding swhid-rs..."
                  fi
                else
                  echo "Cached binary exists but no commit marker found, rebuilding to be safe..."
                fi
              else
                echo "No cached binary found, building swhid-rs..."
              fi
              
              if [ "$NEED_REBUILD" = "true" ]; then
                cargo build --release --features git 2>&1 | tee /tmp/swhid-rs-build.log
              BUILD_EXIT_CODE=${PIPESTATUS[0]}
                if [ $BUILD_EXIT_CODE -eq 0 ]; then
                  REBUILT=true
                  # Ensure binary is executable (Cargo should set this, but be explicit)
                  if [ -f target/release/swhid ]; then
                    chmod +x target/release/swhid
                    echo "‚úÖ Binary built and permissions set"
                  fi
                  # Save the commit hash for future cache validation
                  # Ensure target directory exists and write commit marker
                  mkdir -p target
                  echo "$SWHID_RS_COMMIT" > "$CACHED_COMMIT_FILE"
                  echo "Build completed successfully, saved commit marker to $CACHED_COMMIT_FILE"
                  # Verify the file was written
                  if [ -f "$CACHED_COMMIT_FILE" ]; then
                    echo "Commit marker verified: $(cat "$CACHED_COMMIT_FILE")"
                  else
                    echo "WARNING: Commit marker file was not created!"
                  fi
                fi
              fi
              
              # Set output to indicate if we rebuilt (needed for cache save step)
              echo "swhid_rs_rebuilt=${REBUILT}" >> $GITHUB_OUTPUT
              if [ $BUILD_EXIT_CODE -eq 0 ]; then
                echo "swhid-rs built successfully"
                echo "SWHID_RS_PATH=/tmp/swhid-rs" >> $GITHUB_ENV
                echo "swhid_rs_available=true" >> $GITHUB_ENV
                echo "‚úÖ swhid-rs is available" >> $GITHUB_STEP_SUMMARY
              else
                echo "swhid-rs build failed (exit code: $BUILD_EXIT_CODE)"
                echo "Last 20 lines of build log:"
                tail -20 /tmp/swhid-rs-build.log || true
                echo "swhid_rs_available=false" >> $GITHUB_ENV
                echo "‚ö†Ô∏è swhid-rs build failed" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "swhid-rs repository clone failed (exit code: $CLONE_EXIT_CODE)"
              if [ -f /tmp/swhid-rs-clone.log ]; then
                echo "Clone log:"
                cat /tmp/swhid-rs-clone.log
              fi
              if [ ! -d /tmp/swhid-rs ]; then
                echo "Directory /tmp/swhid-rs does not exist"
              fi
              echo "swhid_rs_available=false" >> $GITHUB_ENV
              echo "‚ÑπÔ∏è swhid-rs repository not accessible - Rust implementation will be skipped" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "SWHID_RS_REPO not configured"
            echo "swhid_rs_available=false" >> $GITHUB_ENV
            echo "‚ÑπÔ∏è SWHID_RS_REPO not configured - Rust implementation will be skipped" >> $GITHUB_STEP_SUMMARY
          fi
          set -e
        continue-on-error: true
      
      - name: Ensure commit marker exists before upload
        if: always() && steps.swhid-rs-setup.outcome == 'success' && steps.swhid-rs-setup.outputs.swhid_rs_rebuilt == 'true'
        shell: bash
        run: |
          echo "=== STEP 1: Ensuring commit marker exists in target directory ==="
          cd /tmp/swhid-rs
          
          # Get commit hash
          SWHID_RS_COMMIT=$(git rev-parse HEAD 2>/dev/null || echo "unknown")
          echo "Current swhid-rs commit: ${SWHID_RS_COMMIT:0:7} (full: $SWHID_RS_COMMIT)"
          
          # Ensure target directory exists
          mkdir -p target
          
          # Create/update commit marker (as hidden file)
          echo "$SWHID_RS_COMMIT" > target/.swhid-rs-commit
          
          # Also create a non-hidden version for artifact inclusion
          echo "$SWHID_RS_COMMIT" > target/swhid-rs-commit.txt
          
          # Verify both were created
          echo ""
          echo "=== Verifying commit markers ==="
          if [ -f target/.swhid-rs-commit ]; then
            echo "‚úÖ Hidden marker created: $(cat target/.swhid-rs-commit)"
            ls -la target/.swhid-rs-commit
          else
            echo "‚ùå ERROR: Failed to create hidden commit marker!"
            exit 1
          fi
          
          if [ -f target/swhid-rs-commit.txt ]; then
            echo "‚úÖ Non-hidden marker created: $(cat target/swhid-rs-commit.txt)"
            ls -la target/swhid-rs-commit.txt
          else
            echo "‚ùå ERROR: Failed to create non-hidden commit marker!"
            exit 1
          fi
          
          # List target directory to verify structure
          echo ""
          echo "=== Target directory structure (all files, including hidden) ==="
          ls -la target/ | head -20 || true
          
          # Check if release directory exists
          if [ -d target/release ]; then
            echo ""
            echo "=== Release directory structure ==="
            ls -la target/release/ | head -10 || true
            # Also copy marker to release directory
            cp target/.swhid-rs-commit target/release/.swhid-rs-commit 2>/dev/null || true
            cp target/swhid-rs-commit.txt target/release/swhid-rs-commit.txt 2>/dev/null || true
            echo "Copied markers to release directory"
          fi
          
          # Find all commit markers
          echo ""
          echo "=== Searching for all commit markers ==="
          find target -name ".swhid-rs-commit" -o -name "swhid-rs-commit.txt" 2>/dev/null | sort || true
        continue-on-error: true
      
      - name: Verify files before artifact upload
        if: always() && steps.swhid-rs-setup.outcome == 'success' && steps.swhid-rs-setup.outputs.swhid_rs_rebuilt == 'true'
        id: verify-upload
        shell: bash
        run: |
          echo "=== STEP 2: Verifying files before artifact upload ==="
          
          # Use SWHID_RS_PATH if available, otherwise default to /tmp/swhid-rs
          SWHID_RS_DIR="${SWHID_RS_PATH:-/tmp/swhid-rs}"
          echo "Using swhid-rs directory: $SWHID_RS_DIR"
          
          cd "$SWHID_RS_DIR"
          
          # Get absolute path for artifact upload (works cross-platform)
          if [ "$RUNNER_OS" == "Windows" ]; then
            # On Windows, convert Unix path to Windows path
            TARGET_DIR=$(cygpath -w "$(pwd)/target" 2>/dev/null || echo "$(pwd)/target")
            # Also try without cygpath if it's not available
            if [ ! -d "$TARGET_DIR" ]; then
              TARGET_DIR="$(pwd)/target"
            fi
          else
            TARGET_DIR="$(pwd)/target"
          fi
          
          echo "Target directory (absolute): $TARGET_DIR"
          echo "target_dir=$TARGET_DIR" >> $GITHUB_OUTPUT
          echo "swhid_rs_dir=$SWHID_RS_DIR" >> $GITHUB_OUTPUT
          
          echo "Checking commit markers:"
          if [ -f target/.swhid-rs-commit ]; then
            echo "‚úÖ Hidden marker exists: $(cat target/.swhid-rs-commit)"
          else
            echo "‚ùå Hidden marker missing!"
          fi
          
          if [ -f target/swhid-rs-commit.txt ]; then
            echo "‚úÖ Non-hidden marker exists: $(cat target/swhid-rs-commit.txt)"
          else
            echo "‚ùå Non-hidden marker missing!"
          fi
          
          echo ""
          echo "Target directory size:"
          du -sh target/ || true
          
          echo ""
          echo "Files to be uploaded (first 20):"
          find target -type f | head -20 || true
          
          # Verify the path exists and is accessible
          if [ ! -d "target" ]; then
            echo "‚ùå ERROR: target directory does not exist at $TARGET_DIR"
            exit 1
          fi
          
          if [ "$RUNNER_OS" == "Windows" ]; then
            # On Windows, also check if swhid.exe exists
            if [ ! -f "target/release/swhid" ] && [ ! -f "target/release/swhid.exe" ]; then
              echo "‚ö†Ô∏è WARNING: swhid binary not found in target/release/"
              ls -la target/release/ || true
            fi
          else
            if [ ! -f "target/release/swhid" ]; then
              echo "‚ö†Ô∏è WARNING: swhid binary not found in target/release/"
              ls -la target/release/ || true
            fi
          fi
        continue-on-error: true
      
      - name: Upload swhid-rs build artifacts (if rebuilt)
        if: always() && steps.swhid-rs-setup.outcome == 'success' && steps.swhid-rs-setup.outputs.swhid_rs_rebuilt == 'true' && steps.verify-upload.outcome == 'success'
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: swhid-rs-target-${{ matrix.os == 'ubuntu-24.04' && 'Linux' || matrix.os == 'macos-14' && 'macOS' || 'Windows' }}
          path: ${{ steps.verify-upload.outputs.target_dir || '/tmp/swhid-rs/target' }}
          retention-days: 1
          if-no-files-found: ignore
          # Note: upload-artifact@v4 may exclude hidden files by default
          # We've created both .swhid-rs-commit (hidden) and swhid-rs-commit.txt (non-hidden)
      
      - name: Run harness unit tests
        run: |
          pytest tests/unit/ tests/integration/ -v --tb=short
      
      - name: Run full test suite (all categories and implementations)
        shell: bash
        run: |
          # Run full test suite with all available implementations
          # The harness will automatically skip implementations that are not available
          echo "Running full test suite (changes detected upstream)..."
          swhid-harness --output-format canonical --dashboard-output results.json || true
          echo "Full test suite completed (some implementations may be skipped)"
      
      - name: Generate HTML results table
        if: always()
        shell: bash
        run: |
          if [ -f results.json ]; then
            python scripts/view_results.py results.json --output results.html || echo "Warning: Could not generate HTML table"
            if [ -f results.html ]; then
              echo "‚úÖ HTML results table generated: results.html" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ö†Ô∏è No results.json file found, skipping HTML generation" >> $GITHUB_STEP_SUMMARY
          fi
        continue-on-error: true
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            results.json
            results.html
          retention-days: 30
      
      - name: Generate test summary
        if: always()
        shell: bash
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f results.json ]; then
            # Generate statistics
            python3 -c "import json; fp=open('results.json'); d=json.load(fp); fp.close(); a=d.get('aggregates',{}); b=a.get('by_implementation',{}); p=sum(s.get('passed',0) for s in b.values()); fa=sum(s.get('failed',0) for s in b.values()); sk=sum(s.get('skipped',0) for s in b.values()); t=p+fa+sk; r=(p/t*100) if t>0 else 0; print(f'| Metric | Value |'); print(f'|--------|-------|'); print(f'| Total Tests | {t} |'); print(f'| Passed | {p} |'); print(f'| Failed | {fa} |'); print(f'| Skipped | {sk} |'); print(f'| Success Rate | {r:.1f}% |') if b else print('| Note | Results format not recognized |')" >> $GITHUB_STEP_SUMMARY 2>&1 || echo "| Note | Error parsing results |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            # Add link to HTML results if available
            if [ -f results.html ]; then
              echo "### üìä Detailed Results" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "üì• Download the [HTML results table](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) from the artifacts." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "The HTML table provides a color-coded view of all test results across all implementations." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "| Note | No results file (harness tests may have been skipped) |" >> $GITHUB_STEP_SUMMARY
          fi

  save-cache:
    needs: [check-changes, test]
    if: always() && needs.check-changes.outputs.changes_detected == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        os_name: [Linux, macOS, Windows]
    steps:
      - name: Download swhid-rs build artifacts for ${{ matrix.os_name }}
        id: download-artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: swhid-rs-target-${{ matrix.os_name }}
          path: /tmp/swhid-rs-cache
      
      - name: Reorganize artifacts to match cache path structure
        if: steps.download-artifacts.outcome == 'success'
        shell: bash
        run: |
          echo "=== STEP 3: Reorganizing artifacts to match cache path structure (${{ matrix.os_name }}) ==="
          echo ""
          echo "Artifact was downloaded to /tmp/swhid-rs-cache"
          echo "We need to reorganize it to /tmp/swhid-rs/target to match restore path"
          echo ""
          
          # Create the target directory structure
          mkdir -p /tmp/swhid-rs
          
          # Check what structure the artifact has
          echo "Checking artifact structure:"
          ls -la /tmp/swhid-rs-cache/ || true
          
          # The artifact might be:
          # 1. /tmp/swhid-rs-cache/target/ (if directory structure preserved)
          # 2. /tmp/swhid-rs-cache/ (if flattened - contains target contents directly)
          
          if [ -d /tmp/swhid-rs-cache/target ]; then
            echo "Artifact has target/ subdirectory - moving to /tmp/swhid-rs/target"
            mv /tmp/swhid-rs-cache/target /tmp/swhid-rs/target
          elif [ -d /tmp/swhid-rs-cache/release ] || [ -f /tmp/swhid-rs-cache/.swhid-rs-commit ] || [ -f /tmp/swhid-rs-cache/swhid-rs-commit.txt ]; then
            echo "Artifact is flattened - contents are directly in /tmp/swhid-rs-cache"
            echo "Moving contents to /tmp/swhid-rs/target"
            mv /tmp/swhid-rs-cache /tmp/swhid-rs/target
          else
            echo "‚ö†Ô∏è Warning: Unexpected artifact structure"
            echo "Attempting to move /tmp/swhid-rs-cache to /tmp/swhid-rs/target"
            mv /tmp/swhid-rs-cache /tmp/swhid-rs/target || true
          fi
          
          echo ""
          echo "Verifying final structure at /tmp/swhid-rs/target:"
          ls -la /tmp/swhid-rs/target/ | head -20 || true
          
          echo ""
          echo "Searching for commit markers:"
          find /tmp/swhid-rs/target -type f \( -name ".swhid-rs-commit" -o -name "swhid-rs-commit.txt" \) 2>/dev/null | sort || echo "No commit markers found"
          
          echo ""
          echo "Finding swhid binary:"
          find /tmp/swhid-rs/target -type f -name "swhid" | head -5 || true
        continue-on-error: true
      
      - name: Verify commit marker before cache save (${{ matrix.os_name }})
        if: steps.download-artifacts.outcome == 'success'
        id: get-commit-hash
        shell: bash
        run: |
          echo "=== STEP 4: Verifying commit marker before cache save (${{ matrix.os_name }}) ==="
          
          # Try to find the commit marker in /tmp/swhid-rs/target (reorganized location)
          COMMIT_MARKER=""
          if [ -f /tmp/swhid-rs/target/.swhid-rs-commit ]; then
            COMMIT_MARKER="/tmp/swhid-rs/target/.swhid-rs-commit"
          elif [ -f /tmp/swhid-rs/target/swhid-rs-commit.txt ]; then
            COMMIT_MARKER="/tmp/swhid-rs/target/swhid-rs-commit.txt"
          elif [ -f /tmp/swhid-rs/target/release/.swhid-rs-commit ]; then
            COMMIT_MARKER="/tmp/swhid-rs/target/release/.swhid-rs-commit"
          elif [ -f /tmp/swhid-rs/target/release/swhid-rs-commit.txt ]; then
            COMMIT_MARKER="/tmp/swhid-rs/target/release/swhid-rs-commit.txt"
          fi
          
          if [ -n "$COMMIT_MARKER" ]; then
            COMMIT_HASH=$(cat "$COMMIT_MARKER" | tr -d '[:space:]')
            echo "‚úÖ Commit marker found at: $COMMIT_MARKER"
            echo "Commit hash: $COMMIT_HASH"
            echo "commit_hash=$COMMIT_HASH" >> $GITHUB_OUTPUT
            
            # Ensure it's in the expected location for cache
            if [ ! -f /tmp/swhid-rs/target/.swhid-rs-commit ]; then
              echo "Creating .swhid-rs-commit in target directory from found marker..."
              mkdir -p /tmp/swhid-rs/target
              cp "$COMMIT_MARKER" /tmp/swhid-rs/target/.swhid-rs-commit
              echo "Created: $(cat /tmp/swhid-rs/target/.swhid-rs-commit)"
            fi
          else
            echo "‚ö†Ô∏è WARNING: No commit marker found in artifact!"
            echo "This may cause cache validation issues."
            # Use a fallback: workflow run ID to make key unique
            echo "commit_hash=${{ github.run_id }}" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true
      
      - name: Save swhid-rs build cache for ${{ matrix.os_name }}
        if: steps.download-artifacts.outcome == 'success' && steps.get-commit-hash.outcome == 'success'
        uses: actions/cache/save@v4
        continue-on-error: true
        with:
          # CRITICAL: Use the same path as restore step to avoid cache version mismatch
          # Restore uses: /tmp/swhid-rs/target
          # Save must use: /tmp/swhid-rs/target (exact same path)
          # GitHub Actions caches are scoped by path - different paths = different cache versions
          path: /tmp/swhid-rs/target
          # Include commit hash in cache key - each commit gets its own cache
          # This allows multiple commits to have caches simultaneously
          # restore-keys with prefix matching will find the most recent cache
          # NOTE: GitHub Actions caches are IMMUTABLE - once created, they cannot be overwritten.
          # If a cache with this exact key already exists, the save will fail with "Unable to reserve cache".
          # This is expected and harmless (continue-on-error handles it) - it means we already have this cache.
          key: swhid-rs-${{ matrix.os_name }}-stable-multi-platform-workflow-${{ steps.get-commit-hash.outputs.commit_hash }}
      
      - name: Debug cache save result (${{ matrix.os_name }})
        if: steps.download-artifacts.outcome == 'success' && steps.get-commit-hash.outcome == 'success'
        shell: bash
        run: |
          echo "Cache save completed (check logs above for any errors)"
          echo "Cache key used: swhid-rs-${{ matrix.os_name }}-stable-multi-platform-workflow-${{ steps.get-commit-hash.outputs.commit_hash }}"
          echo "Cache path: /tmp/swhid-rs/target"
          if [ -d /tmp/swhid-rs/target ]; then
            echo "‚úÖ Target directory exists and will be cached"
            du -sh /tmp/swhid-rs/target || true
          else
            echo "‚ùå Target directory does not exist"
          fi
        continue-on-error: true


  publish-dashboard:
    needs: [check-changes, test, save-cache]
    if: github.ref == 'refs/heads/main' && needs.check-changes.outputs.changes_detected == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      pages: write
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
          cache: 'pip'  # Automatically cache pip packages
          # Note: setup-python@v5 handles pip caching automatically, no need for explicit cache step
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      
      - name: Merge results
        shell: bash
        run: |
          # Create a simple HTML summary if merge_results.py doesn't exist
          if [ -f tools/merge_results.py ]; then
            python tools/merge_results.py artifacts/**/results.json --site site
          else
            mkdir -p site
            echo "<html><body><h1>Test Results</h1><p>Results are available in the artifacts.</p></body></html>" > site/index.html
          fi
      
      - name: Generate dashboard
        shell: bash
        run: |
          python -m tools.dashboard \
            --site site \
            --data site/data \
            --artifacts artifacts
      
      - name: Check if Pages is enabled
        id: pages-check
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            try {
              // Check if pages API is available
              if (!github.rest || !github.rest.pages) {
                console.log('‚ö† Pages API not available in this context');
                console.log('‚ö† Attempting to proceed with Pages deployment anyway');
                console.log('‚ö† If deployment fails, ensure Pages is enabled in repository settings');
                core.setOutput('enabled', 'true'); // Try anyway
                return;
              }
              
              const pages = await github.rest.pages.get({ 
                owner: context.repo.owner, 
                repo: context.repo.repo 
              });
              
              console.log('Pages status:', JSON.stringify(pages.data, null, 2));
              
              // Check if Pages is configured for GitHub Actions
              if (pages.data && pages.data.source) {
                if (pages.data.source.type === 'workflow') {
                  console.log('‚úì Pages is configured for GitHub Actions');
                  core.setOutput('enabled', 'true');
                } else if (pages.data.source.type === 'branch') {
                  console.log('‚ö† Pages is configured for branch deployment, not GitHub Actions');
                  console.log('‚ö† Please change Pages source to "GitHub Actions" in repository settings');
                  console.log('‚ö† Please change Pages source to "GitHub Actions" in repository settings');
                  core.setOutput('enabled', 'false');
                } else {
                  console.log('‚ö† Pages source type unknown:', pages.data.source.type);
                  console.log('‚ö† Attempting to proceed anyway');
                  core.setOutput('enabled', 'true'); // Try anyway
                }
              } else {
                console.log('‚ö† Pages data structure unexpected, attempting to proceed');
                core.setOutput('enabled', 'true'); // Try anyway
              }
            } catch (error) {
              console.log('‚ö† Pages API call failed, but attempting to proceed');
              console.log('Error:', error.message);
              console.log('');
              console.log('Note: If Pages deployment fails, ensure:');
              console.log('1. Pages is enabled in Settings ‚Üí Pages');
              console.log('2. Pages source is set to "GitHub Actions"');
              console.log('3. Ensure Pages is enabled and configured for GitHub Actions');
              // Try to proceed anyway - let configure-pages handle the actual check
              core.setOutput('enabled', 'true');
            }
      
      - name: Configure Pages
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/configure-pages@v5
        continue-on-error: true
      
      - name: Verify site structure
        if: steps.pages-check.outputs.enabled == 'true'
        shell: bash
        run: |
          echo "Verifying site structure..."
          if [ ! -f site/index.html ]; then
            echo "ERROR: site/index.html not found!"
            echo "Site contents:"
            ls -la site/ || true
            find site/ -type f | head -20
            exit 1
          fi
          echo "‚úì site/index.html exists"
          if [ -d site/data ]; then
            echo "‚úì site/data/ directory exists"
            ls -la site/data/ || true
          fi
          if [ -d site/assets ]; then
            echo "‚úì site/assets/ directory exists"
          fi
      
      - name: Upload Pages artifact
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: site
        continue-on-error: true
      
      - name: Deploy to GitHub Pages
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/deploy-pages@v4
        continue-on-error: true

  performance-baseline:
    needs: test
    runs-on: ubuntu-24.04
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Update performance baselines
        run: |
          echo "Performance baseline update would go here"
          # This would update baseline performance files
          # and detect regressions

